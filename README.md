# ğŸš€ DataGenius PRO - Next-Gen Auto Data Scientist

![Version](https://img.shields.io/badge/version-2.0.0-blue)
![Python](https://img.shields.io/badge/python-3.11+-green)
![License](https://img.shields.io/badge/license-MIT-orange)

**DataGenius PRO** to zaawansowana platforma do automatycznej analizy danych i Machine Learning, wyposaÅ¼ona w inteligentne agenty AI i AI Mentora mÃ³wiÄ…cego po polsku.

## âœ¨ Kluczowe Funkcje

### ğŸ¤– Automatyczne AI Agents
- **Data Understanding Agent**: Automatyczna detekcja typu problemu i kolumny target
- **EDA Agent**: Kompleksowa analiza eksploracyjna danych
- **ML Agent**: Automatyczne trenowanie i tuning modeli (PyCaret)
- **AI Mentor**: Asystent tÅ‚umaczÄ…cy wyniki po polsku (Claude AI)

### ğŸ“Š Continuous Monitoring
- Wykrywanie model drift i concept drift
- Performance tracking w czasie rzeczywistym
- Automatyczne alerty
- Scheduler do retrainingu

### ğŸ“š Pipeline Registry
- Historia wszystkich sesji i eksperymentÃ³w
- Wersjonowanie modeli
- Reprodukowalne eksperymenty
- Export do MLflow/Weights & Biases

### ğŸ“„ Auto Reports
- Raporty EDA (PDF/HTML)
- ML performance reports
- Monitoring dashboards
- Scheduled delivery

---

## ğŸ› ï¸ Tech Stack

### Core
- **Python 3.11+**
- **Streamlit** - Interactive UI
- **PyCaret** - AutoML framework
- **Anthropic Claude / OpenAI GPT** - LLM dla AI Mentora

### Data & ML
- **Pandas, Polars** - Data manipulation
- **Scikit-learn** - ML algorithms
- **XGBoost, LightGBM, CatBoost** - Gradient boosting
- **SHAP, LIME** - Model interpretability
- **Plotly** - Interactive visualizations

### Infrastructure
- **PostgreSQL / SQLite** - Database
- **Redis** - Caching
- **Docker** - Containerization
- **MLflow** - Experiment tracking

---

## ğŸ“¦ Instalacja

### 1. Clone Repository
```bash
git clone https://github.com/your-org/datagenius-pro.git
cd datagenius-pro
```

### 2. Setup Environment

#### Opcja A: Conda/Mamba (rekomendowane)
```bash
conda env create -f environment.yml
conda activate datagenius-pro
```

#### Opcja B: pip + venv
```bash
python -m venv venv
source venv/bin/activate  # Linux/Mac
# lub
venv\Scripts\activate  # Windows

pip install -r requirements.txt
```

### 3. Konfiguracja

Skopiuj template i wypeÅ‚nij swoimi danymi:
```bash
cp .env.template .env
```

Edytuj `.env` i dodaj swoje klucze API:
```bash
ANTHROPIC_API_KEY=your_anthropic_key_here
OPENAI_API_KEY=your_openai_key_here  # opcjonalne
```

### 4. Inicjalizacja Bazy Danych
```bash
python scripts/init_db.py
```

### 5. Uruchom AplikacjÄ™
```bash
streamlit run app.py
```

Aplikacja bÄ™dzie dostÄ™pna pod: `http://localhost:8501`

---

## ğŸš€ Quick Start

### 1. ZaÅ‚aduj Dane
- PrzeÅ›lij swÃ³j CSV/Excel/JSON
- Lub wybierz przykÅ‚adowy dataset (Iris, Titanic, House Prices)

### 2. Eksploracja (EDA)
- Automatyczna analiza statystyczna
- Wykrywanie outliers i brakÃ³w danych
- Interaktywne wizualizacje
- Analiza korelacji

### 3. Trenowanie Modelu
- Automatyczne porÃ³wnanie 15+ algorytmÃ³w
- Hyperparameter tuning
- Feature importance (SHAP)
- Explainable AI

### 4. AI Mentor
- Zadawaj pytania po polsku
- Otrzymuj wyjaÅ›nienia wynikÃ³w
- Konkretne rekomendacje
- Pomoc w feature engineering

### 5. Monitoring
- Åšledzenie performance
- Drift detection
- Automatyczne alerty

---

## ğŸ“ Struktura Projektu

```
datagenius-pro/
â”‚
â”œâ”€â”€ app.py                      # ğŸ¯ GÅ‚Ã³wny punkt wejÅ›cia
â”œâ”€â”€ requirements.txt            # ğŸ“¦ ZaleÅ¼noÅ›ci
â”œâ”€â”€ environment.yml             # ğŸ Conda environment
â”œâ”€â”€ Makefile                    # ğŸ› ï¸ Automation commands
â”‚
â”œâ”€â”€ config/                     # âš™ï¸ Konfiguracja
â”‚   â”œâ”€â”€ settings.py            # Centralny config (Pydantic)
â”‚   â”œâ”€â”€ logging_config.py      # Logowanie
â”‚   â”œâ”€â”€ model_registry.py      # Rejestr modeli ML
â”‚   â””â”€â”€ constants.py           # StaÅ‚e aplikacji
â”‚
â”œâ”€â”€ core/                       # ğŸ§  RdzeÅ„ aplikacji
â”‚   â”œâ”€â”€ base_agent.py          # Bazowa klasa agentÃ³w
â”‚   â”œâ”€â”€ llm_client.py          # Wrapper dla LLM
â”‚   â”œâ”€â”€ data_loader.py         # Loader danych
â”‚   â”œâ”€â”€ data_validator.py      # Walidacja danych
â”‚   â”œâ”€â”€ state_manager.py       # Session state
â”‚   â””â”€â”€ utils.py               # Utility functions
â”‚
â”œâ”€â”€ agents/                     # ğŸ¤– AI Agents
â”‚   â”œâ”€â”€ data_understanding/    # Agent rozumienia danych
â”‚   â”œâ”€â”€ eda/                   # Agent EDA
â”‚   â”œâ”€â”€ preprocessing/         # Agent preprocessingu
â”‚   â”œâ”€â”€ ml/                    # Agent ML
â”‚   â”œâ”€â”€ monitoring/            # Agent monitoringu
â”‚   â””â”€â”€ mentor/                # AI Mentor
â”‚
â”œâ”€â”€ frontend/                   # ğŸ¨ Frontend (Streamlit)
â”‚   â”œâ”€â”€ pages/                 # Strony aplikacji
â”‚   â”œâ”€â”€ components/            # Komponenty UI
â”‚   â””â”€â”€ styling/               # Style i theme
â”‚
â”œâ”€â”€ db/                         # ğŸ—„ï¸ Database
â”‚   â”œâ”€â”€ models.py              # SQLAlchemy models
â”‚   â”œâ”€â”€ crud.py                # CRUD operations
â”‚   â””â”€â”€ schemas/               # SQL schemas
â”‚
â”œâ”€â”€ tests/                      # ğŸ§ª Testy
â”‚   â”œâ”€â”€ unit/                  # Testy jednostkowe
â”‚   â”œâ”€â”€ integration/           # Testy integracyjne
â”‚   â””â”€â”€ e2e/                   # Testy end-to-end
â”‚
â”œâ”€â”€ docs/                       # ğŸ“š Dokumentacja
â”‚   â”œâ”€â”€ ARCHITECTURE.md        # Architektura systemu
â”‚   â”œâ”€â”€ API.md                 # Dokumentacja API
â”‚   â””â”€â”€ guides/                # Przewodniki
â”‚
â””â”€â”€ data/                       # ğŸ“Š Dane
    â”œâ”€â”€ samples/               # PrzykÅ‚adowe datasety
    â”œâ”€â”€ uploads/               # PrzesÅ‚ane pliki
    â””â”€â”€ processed/             # Przetworzone dane
```

---

## ğŸ¯ PrzykÅ‚ady UÅ¼ycia

### Podstawowy Workflow

```python
from core.data_loader import get_data_loader
from agents.eda.eda_orchestrator import EDAOrchestrator
from agents.ml.ml_orchestrator import MLOrchestrator

# 1. ZaÅ‚aduj dane
loader = get_data_loader()
data = loader.load("data/samples/iris.csv")

# 2. EDA
eda_agent = EDAOrchestrator()
eda_results = eda_agent.run(data=data, target_column="species")

# 3. Trenuj model
ml_agent = MLOrchestrator()
ml_results = ml_agent.run(
    data=data,
    target_column="species",
    problem_type="classification"
)

# 4. Wyniki
print(f"Best Model: {ml_results.data['summary']['best_model']}")
print(f"Accuracy: {ml_results.data['summary']['best_score']:.4f}")
```

### AI Mentor

```python
from agents.mentor.mentor_orchestrator import MentorOrchestrator

mentor = MentorOrchestrator()

# Zapytaj AI Mentora
response = mentor.run(
    query="Jak mogÄ™ poprawiÄ‡ wyniki mojego modelu?",
    context={
        "ml_results": ml_results.data,
        "eda_results": eda_results.data
    }
)

print(response.data["response"])
```

---

## ğŸ”§ Konfiguracja

### Environment Variables

NajwaÅ¼niejsze zmienne w `.env`:

```bash
# LLM API Keys
ANTHROPIC_API_KEY=sk-ant-...
OPENAI_API_KEY=sk-...

# Database
DATABASE_URL=postgresql://user:pass@localhost:5432/datagenius
# lub SQLite dla developmentu
DATABASE_URL=sqlite:///./data/datagenius.db

# ML Settings
ENABLE_HYPERPARAMETER_TUNING=true
ENABLE_ENSEMBLE=true
MAX_TRAINING_TIME_MINUTES=30

# Monitoring
ENABLE_MONITORING=true
MONITORING_SCHEDULE=weekly

# Feature Flags
ENABLE_AI_MENTOR=true
ENABLE_AUTO_EDA=true
ENABLE_AUTO_ML=true
```

---

## ğŸ³ Docker

### Build i Run

```bash
# Build image
docker-compose build

# Start containers
docker-compose up -d

# View logs
docker-compose logs -f

# Stop
docker-compose down
```

Aplikacja bÄ™dzie dostÄ™pna pod: `http://localhost:8501`

---

## ğŸ§ª Testing

### Uruchom wszystkie testy
```bash
make test
```

### Testy jednostkowe
```bash
pytest tests/unit/ -v
```

### Testy integracyjne
```bash
pytest tests/integration/ -v
```

### Coverage
```bash
pytest --cov=. --cov-report=html
```

---

## ğŸ“Š Monitoring & MLOps

### MLflow Integration

```bash
# Start MLflow server
mlflow ui --backend-store-uri sqlite:///mlflow.db

# W .env
ENABLE_MLFLOW_LOGGING=true
MLFLOW_TRACKING_URI=http://localhost:5000
```

### Weights & Biases

```bash
# W .env
ENABLE_WANDB_LOGGING=true
WANDB_API_KEY=your_wandb_key
WANDB_PROJECT=datagenius-pro
```

---

## ğŸ¤ Contributing

Contributions are welcome! Please read [CONTRIBUTING.md](docs/CONTRIBUTING.md) for guidelines.

### Development Setup

```bash
# Install dev dependencies
pip install -r requirements-dev.txt

# Setup pre-commit hooks
pre-commit install

# Run linters
make lint

# Format code
make format
```

---

## ğŸ“ License

MIT License - see [LICENSE](LICENSE) file for details.

---

## ğŸ‘¥ Team

### ZespoÅ‚y
- **Z1 - EDA**: Exploratory Data Analysis
- **Z2 - ML**: Machine Learning Pipeline
- **Z3 - Backend**: Application Logic
- **Z4 - Frontend**: Streamlit UI
- **Z5 - Database**: Data Persistence
- **Z6 - QA**: Testing & Deployment
- **Z7 - UX/Docs**: UX Design & Documentation

---

## ğŸ“ Support

- ğŸ“§ Email: support@datagenius-pro.com
- ğŸ’¬ Discord: [Join our community](https://discord.gg/datagenius)
- ğŸ™ GitHub Issues: [Report a bug](https://github.com/datagenius-pro/issues)
- ğŸ“š Documentation: [docs.datagenius-pro.com](https://docs.datagenius-pro.com)

---

## ğŸ—ºï¸ Roadmap

### v2.1 (Q1 2025)
- [ ] Multi-user support
- [ ] Real-time predictions API
- [ ] Advanced ensemble methods
- [ ] Custom model marketplace

### v2.2 (Q2 2025)
- [ ] Deep Learning support
- [ ] Time series forecasting
- [ ] AutoML hyperparameter optimization
- [ ] Multi-language support

### v3.0 (Q3 2025)
- [ ] Enterprise features
- [ ] Role-based access control
- [ ] Advanced integrations
- [ ] Cloud deployment options

---

## â­ Star History

If you find this project useful, please consider giving it a star! â­

---

**Built with â¤ï¸ by DataGenius Team**

*Making Data Science accessible to everyone!*